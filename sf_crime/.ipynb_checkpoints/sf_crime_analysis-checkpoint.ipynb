{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gmaps\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "from app_token import sf_crime_token\n",
    "from datetime import date, datetime, timedelta\n",
    "from config import g_key\n",
    "gmaps.configure(api_key=g_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API Request and Response\n",
    "Resource: https://dev.socrata.com/foundry/data.sfgov.org/wg3w-h783"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL\n",
    "base_url = 'https://data.sfgov.org/resource/wg3w-h783.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query string\n",
    "token = f'$$app_token={sf_crime_token}'\n",
    "order = '$order=incident_datetime ASC'\n",
    "limit = '$limit=1000000'\n",
    "\n",
    "# Date parameter\n",
    "lockdown_date = date(2020,3,17)\n",
    "start_date = lockdown_date-timedelta(days=366)\n",
    "end_date = lockdown_date+timedelta(days=364)\n",
    "date_range = f\"incident_date between '{start_date}' and '{end_date}'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request URL\n",
    "request_url = f'{base_url}?{token}&{order}&{limit}&$where={date_range}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store response in DataFrame\n",
    "data = requests.get(request_url).json()\n",
    "data_df = pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check uniqueness\n",
    "row_count = len(data_df.index)\n",
    "print(f'Total Rows: {row_count}')\n",
    "\n",
    "row_id_count = data_df['row_id'].nunique()\n",
    "print(f'Unique Row IDs: {row_id_count}')\n",
    "\n",
    "incident_id_count = data_df['incident_id'].nunique()\n",
    "print(f'Unique Incident IDs: {incident_id_count}')\n",
    "\n",
    "columns = ['incident_id', 'incident_datetime', 'report_datetime', 'incident_number', 'police_district', \\\n",
    "           'analysis_neighborhood', 'latitude', 'longitude']\n",
    "subset_1_row_count = len(data_df[columns].drop_duplicates().index)\n",
    "print(f'Subset 1 Rows: {subset_1_row_count}')\n",
    "\n",
    "columns.append('incident_category')\n",
    "subset_2_row_count = len(data_df[columns].drop_duplicates().index)\n",
    "print(f'Subset 2 Rows: {subset_2_row_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finding: Records are unique and identifiable by 'row_id'. However, each record does not correspond to a unique incident. While each 'incident_id' may have only one value for 'incident_datetime', 'report_datetime', 'incident_number', 'police_district', 'analysis_neighborhood', 'supervisor district', 'latitude', and 'longitude', it may be duplicated on 'incident_category' when the incident involves multiple offenses (e.g., illegal possession of drugs and weapons).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check completeness\n",
    "data_df.count() / row_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finding: The dataset is sufficiently comprehensive because it captures key incident details such as date, time, category, and location. Furthermore, the frequency of missing values did not exceed 5% for any significant column. Additional details about the perpetrator and victim would have been interesting.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check timeliness\n",
    "# Resource: https://www.datasciencemadesimple.com/difference-two-timestamps-seconds-minutes-hours-pandas-python-2/\n",
    "time_df = data_df[['incident_id', 'report_datetime', 'incident_datetime']].drop_duplicates()\n",
    "time_df[['report_datetime', 'incident_datetime']] = time_df[['report_datetime', 'incident_datetime']].apply(pd.to_datetime)\n",
    "time_df['diff_datetime'] = time_df['report_datetime'] - time_df['incident_datetime']\n",
    "time_df['diff_hours'] = time_df['diff_datetime'] / np.timedelta64(1,'h')\n",
    "\n",
    "quantiles = np.arange(0.05, 1, 0.05)\n",
    "for item in quantiles:\n",
    "    value = time_df['diff_hours'].quantile(item)\n",
    "    print(f\"Quantile {'{:.2f}'.format(item)}: {'{:.2f}'.format(value)} Hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finding: Incident reports are filed in a timely manner. The median elapsed time from incident occurrence to report filing is a mere 3 hours and 26 minutes. Q<sub>1</sub> = 7 minutes and Q<sub>3</sub> = 30 hours and 40 minutes. Once filed, incident reports are published via an automated daily update.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check consistency\n",
    "# Resource: https://towardsdatascience.com/master-the-most-hated-task-in-ds-ml-3b9779276d7c\n",
    "incident_categories = data_df['incident_category'].value_counts().sort_index()\n",
    "print(incident_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "police_districts = data_df['police_district'].value_counts().sort_index()\n",
    "print(police_districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighborhoods = data_df['analysis_neighborhood'].value_counts().sort_index()\n",
    "print(neighborhoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finding: In 'incident_category', multiple inconsistencies exists: the word \"Offense\" is sometimes spelled \"Offence\", a \"?\" is appended to \"Motor Vehicle Theft\", and \"(A)\" is inserted into \"Human Trafficking, Commercial Sex Acts.\" Furthermore, the field requires grouping of several categories: \"Drug Violation\" into \"Drug Offense\", \"Other\" and \"Other Offenses\" into \"Other Miscellaneous\", \"Suspicious\" into \"Suspicious Occ\", and \"Weapons Carrying Etc\" into \"Weapons Offense\". In 'analysis_neighborhood', an inconsistency exists across \"null\" and blank values; they are two representations of the same value.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Cleansing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "data_df.fillna({'analysis_neighborhood':'Not Disclosed', 'incident_category':'Not Disclosed'}, inplace=True)\n",
    "data_df['analysis_neighborhood'].replace('null','Not Disclosed', inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix typos\n",
    "data_df['incident_category'].replace(['Offence','\\?',' \\(A\\)'],['Offense','',''], inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group similar categories\n",
    "data_df['incident_category'].replace(['Drug Violation','Other','Other Offenses','Suspicious','Weapons Carrying Etc'], \\\n",
    "                                     ['Drug Offense','Other Miscellaneous','Other Miscellaneous','Suspicious Occ', 'Weapons Offense'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by pre and post lockdown\n",
    "pre_df = data_df.loc[data_df['incident_date'] < lockdown_date.strftime('%Y-%m-%d')]\n",
    "post_df = data_df.loc[data_df['incident_date'] >= lockdown_date.strftime('%Y-%m-%d')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Category Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group total incidents by category\n",
    "pre_cat_ser = pre_df.groupby('incident_category')['incident_id'].nunique().rename('pre_incidents')\n",
    "post_cat_ser = post_df.groupby('incident_category')['incident_id'].nunique().rename('post_incidents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate pre and post incidents, calculate percent change\n",
    "cat_df = pd.concat([pre_cat_ser, post_cat_ser], sort=True, axis=1).fillna(0)\n",
    "cat_df['post_incidents'] = cat_df['post_incidents'].astype(int)\n",
    "cat_df.drop(labels='Not Disclosed', axis=0, inplace=True)\n",
    "cat_df['percent_change'] = (cat_df['post_incidents'] - cat_df['pre_incidents']) / cat_df['pre_incidents'] * 100\n",
    "cat_df.sort_values(by=['post_incidents'], ascending=True, inplace=True)\n",
    "cat_df.index = cat_df.index + ' (' + cat_df['post_incidents'].astype(str) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(cat_df.index, cat_df['percent_change'], height=0.5, color='royalblue', align='center')\n",
    "plt.title(f'Category Incidents Post-Lockdown')\n",
    "plt.xlabel('Percent Change YOY')\n",
    "plt.ylabel('Category (Incidents)')\n",
    "plt.xlim(-100, max(100, cat_df['percent_change'].max()))\n",
    "plt.ylim(-0.5, len(cat_df.index)-0.5)\n",
    "plt.tick_params(axis='y',left=False)\n",
    "plt.grid(axis='x', linestyle='--', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/incidents_category.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Narrow Scope to Crimes of Stolen Property Only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stolen_types = ['Burglary', 'Larceny Theft', 'Lost Property', 'Motor Vehicle Theft', 'Robbery', 'Stolen Property']\n",
    "#stolen_types = ['Burglary']\n",
    "stolen_pre_df = pre_df.loc[data_df['incident_category'].isin(stolen_types)]\n",
    "stolen_post_df = post_df.loc[data_df['incident_category'].isin(stolen_types)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Map Analysis**<br>\n",
    "Resource: https://jupyter-gmaps.readthedocs.io/en/latest/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map incidents by latitude and longitude\n",
    "def map_incidents(df):\n",
    "    latlong_df = df[['incident_id', 'latitude', 'longitude']].copy().drop_duplicates().dropna(how='any')\n",
    "    locations = latlong_df[['latitude', 'longitude']].astype(float)\n",
    "    fig_layout_dict = {'width':'1000px', 'height':'1000px', 'border':'1px solid black', 'padding':'5px'}\n",
    "    fig = gmaps.figure(layout=fig_layout_dict)\n",
    "    heat_layer = gmaps.heatmap_layer(locations, dissipating=True, max_intensity=5, point_radius=5)\n",
    "    fig.add_layer(heat_layer)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map pre-lockdown incidents\n",
    "map_incidents(stolen_pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map post-lockdown incidents\n",
    "map_incidents(stolen_post_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neighborhood Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group incidents by neighborhood\n",
    "def chart_neighborhood_incidents(df, timing):\n",
    "    district_ser = df.groupby('analysis_neighborhood')['incident_id'].nunique()\n",
    "    district_ser.sort_values(ascending=True, inplace=True)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.barh(district_ser.index, district_ser, height=0.5, color='royalblue', align='center')\n",
    "    plt.title(f'Neighborhood Incidents {timing}-Lockdown')\n",
    "    plt.xlabel('Incidents')\n",
    "    plt.ylabel('Neighborhood')\n",
    "    plt.ylim(-0.5, len(district_ser)-0.5)\n",
    "    plt.tick_params(axis='y',left=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/incidents_neighborhood_{timing.lower()}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart pre-lockdown incidents\n",
    "chart_neighborhood_incidents(stolen_pre_df, 'Pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Chart post-lockdown incidents\n",
    "chart_neighborhood_incidents(stolen_post_df, 'Post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group total incidents by day and hour\n",
    "def chart_time_incidents(start_date, end_date, df, timing):\n",
    "    \n",
    "    # Count occurrence of each day of week within date range\n",
    "    # Resource: https://numpy.org/doc/stable/reference/generated/numpy.busday_count.html\n",
    "    days_dict = {}\n",
    "    def day_counter(start_date, end_date, day):\n",
    "        day_count = np.busday_count(start_date, end_date+timedelta(days=1), weekmask=day)\n",
    "        return day_count\n",
    "    for day in days:\n",
    "        days_dict[day] = day_counter(start_date, end_date, day)\n",
    "    \n",
    "    # Group total incidents by day and hour\n",
    "    # Resource: https://www.javaer101.com/en/article/17171715.html\n",
    "    time_df = df[['incident_day_of_week', 'incident_time', 'incident_id']].copy().drop_duplicates()\n",
    "    day_cats = pd.api.types.CategoricalDtype(categories=days, ordered=True)\n",
    "    time_df['day_abbr'] = time_df['incident_day_of_week'].str[:3].astype(day_cats)\n",
    "    time_df['incident_hour'] = time_df['incident_time'].str[:2].astype(int)\n",
    "    time_ser = time_df.groupby(['day_abbr', 'incident_hour'])['incident_id'].nunique().astype(float)\n",
    "    \n",
    "    # Convert total incidents to average incidents by weekday and hour\n",
    "    def day_count_divisor(day):\n",
    "        time_ser[day] = time_ser.loc[day].divide(days_dict[day], level='day_abbr')\n",
    "    for day in days:\n",
    "        day_count_divisor(day)\n",
    "\n",
    "    # Plot\n",
    "    time_ser.unstack(level=0).plot(\n",
    "        kind='line',\n",
    "        figsize=(12,8),\n",
    "        title=f'Average Hourly Incidents {timing}-Lockdown')\n",
    "    plt.xlabel('Hour')\n",
    "    plt.ylabel('Average Incidents')\n",
    "    plt.ylim(0, time_ser.max()*1.2)\n",
    "    plt.xticks(np.arange(0,24,2))\n",
    "    plt.legend(title='Day of Week')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/incidents_hourly_{timing.lower()}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chart_time_incidents(start_date, lockdown_date-timedelta(days=1), stolen_pre_df, 'Pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_time_incidents(lockdown_date, end_date, stolen_post_df, 'Post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
