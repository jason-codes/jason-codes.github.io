{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gmaps\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "from app_token import sf_crime_token\n",
    "from datetime import date, datetime, timedelta\n",
    "from config import g_key\n",
    "gmaps.configure(api_key=g_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Request\n",
    "Resource: https://dev.socrata.com/foundry/data.sfgov.org/wg3w-h783"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base URL\n",
    "base_url = 'https://data.sfgov.org/resource/wg3w-h783.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query string\n",
    "token = f'$$app_token={sf_crime_token}'\n",
    "order = '$order=incident_datetime ASC'\n",
    "limit = '$limit=1000000'\n",
    "\n",
    "# Date parameter\n",
    "lockdown_date = date(2020,3,17)\n",
    "start_date = lockdown_date-timedelta(days=366)\n",
    "end_date = lockdown_date+timedelta(days=364)\n",
    "date_range = f\"incident_date between '{start_date}' and '{end_date}'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request URL\n",
    "request_url = f'{base_url}?{token}&{order}&{limit}&$where={date_range}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store response in DataFrame\n",
    "data = requests.get(request_url).json()\n",
    "data_df = pd.DataFrame.from_records(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows: 260291\n",
      "Unique Row IDs: 260291\n",
      "Unique Incident IDs: 215962\n",
      "Subset 1 Rows: 215962\n",
      "Subset 2 Rows: 251582\n"
     ]
    }
   ],
   "source": [
    "# Check uniqueness\n",
    "row_count = len(data_df.index)\n",
    "print(f'Total Rows: {row_count}')\n",
    "\n",
    "row_id_count = data_df['row_id'].nunique()\n",
    "print(f'Unique Row IDs: {row_id_count}')\n",
    "\n",
    "incident_id_count = data_df['incident_id'].nunique()\n",
    "print(f'Unique Incident IDs: {incident_id_count}')\n",
    "\n",
    "columns = ['incident_id', 'incident_datetime', 'report_datetime', 'incident_number', 'police_district', \\\n",
    "           'analysis_neighborhood', 'latitude', 'longitude']\n",
    "subset_1_row_count = len(data_df[columns].drop_duplicates().index)\n",
    "print(f'Subset 1 Rows: {subset_1_row_count}')\n",
    "\n",
    "columns.append('incident_category')\n",
    "subset_2_row_count = len(data_df[columns].drop_duplicates().index)\n",
    "print(f'Subset 2 Rows: {subset_2_row_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finding: Records are unique and identifiable by 'row_id'. However, each record does not correspond to a unique incident. While each 'incident_id' may have only one value for 'incident_datetime', 'report_datetime', 'incident_number', 'police_district', 'analysis_neighborhood', 'supervisor district', 'latitude', and 'longitude', it may be duplicated on 'incident_category' when the incident involves multiple offenses (e.g., illegal possession of drugs and weapons).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "incident_datetime          1.000000\n",
       "incident_date              1.000000\n",
       "incident_time              1.000000\n",
       "incident_year              1.000000\n",
       "incident_day_of_week       1.000000\n",
       "report_datetime            1.000000\n",
       "row_id                     1.000000\n",
       "incident_id                1.000000\n",
       "incident_number            1.000000\n",
       "report_type_code           1.000000\n",
       "report_type_description    1.000000\n",
       "filed_online               0.189668\n",
       "incident_code              1.000000\n",
       "incident_category          0.998717\n",
       "incident_subcategory       0.998717\n",
       "incident_description       1.000000\n",
       "resolution                 1.000000\n",
       "intersection               0.950148\n",
       "cnn                        0.950148\n",
       "police_district            1.000000\n",
       "analysis_neighborhood      0.950148\n",
       "supervisor_district        0.950148\n",
       "latitude                   0.950148\n",
       "longitude                  0.950148\n",
       "point                      0.950148\n",
       "cad_number                 0.789440\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check completeness\n",
    "data_df.count() / row_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finding: The dataset is sufficiently comprehensive because it captures key incident details such as date, time, category, and location. Furthermore, the frequency of missing values did not exceed 5% for any significant column. Additional details about the perpetrator and victim would have been interesting.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile 0.05: 0.00 Hours\n",
      "Quantile 0.10: 0.00 Hours\n",
      "Quantile 0.15: 0.00 Hours\n",
      "Quantile 0.20: 0.05 Hours\n",
      "Quantile 0.25: 0.12 Hours\n",
      "Quantile 0.30: 0.23 Hours\n",
      "Quantile 0.35: 0.50 Hours\n",
      "Quantile 0.40: 1.10 Hours\n",
      "Quantile 0.45: 2.03 Hours\n",
      "Quantile 0.50: 3.43 Hours\n",
      "Quantile 0.55: 6.18 Hours\n",
      "Quantile 0.60: 11.13 Hours\n",
      "Quantile 0.65: 15.60 Hours\n",
      "Quantile 0.70: 21.03 Hours\n",
      "Quantile 0.75: 30.72 Hours\n",
      "Quantile 0.80: 51.35 Hours\n",
      "Quantile 0.85: 92.97 Hours\n",
      "Quantile 0.90: 184.90 Hours\n",
      "Quantile 0.95: 526.02 Hours\n"
     ]
    }
   ],
   "source": [
    "# Check timeliness\n",
    "# Resource: https://www.datasciencemadesimple.com/difference-two-timestamps-seconds-minutes-hours-pandas-python-2/\n",
    "time_df = data_df[['incident_id', 'report_datetime', 'incident_datetime']].drop_duplicates()\n",
    "time_df[['report_datetime', 'incident_datetime']] = time_df[['report_datetime', 'incident_datetime']].apply(pd.to_datetime)\n",
    "time_df['diff_datetime'] = time_df['report_datetime'] - time_df['incident_datetime']\n",
    "time_df['diff_hours'] = time_df['diff_datetime'] / np.timedelta64(1,'h')\n",
    "\n",
    "quantiles = np.arange(0.05, 1, 0.05)\n",
    "for item in quantiles:\n",
    "    value = time_df['diff_hours'].quantile(item)\n",
    "    print(f\"Quantile {'{:.2f}'.format(item)}: {'{:.2f}'.format(value)} Hours\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finding: Incident reports are filed in a timely manner. The median elapsed time from incident occurrence to report filing is a mere 3 hours and 26 minutes. Q<sub>1</sub> = 7 minutes and Q<sub>3</sub> = 30 hours and 40 minutes. Once filed, incident reports are published via an automated daily update.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arson                                           785\n",
      "Assault                                       15603\n",
      "Burglary                                      16111\n",
      "Case Closure                                   1072\n",
      "Civil Sidewalks                                 248\n",
      "Courtesy Report                                 762\n",
      "Disorderly Conduct                             4432\n",
      "Drug Offense                                   6062\n",
      "Drug Violation                                   87\n",
      "Embezzlement                                    347\n",
      "Fire Report                                     363\n",
      "Forgery And Counterfeiting                      926\n",
      "Fraud                                          7870\n",
      "Gambling                                          5\n",
      "Homicide                                         29\n",
      "Human Trafficking (A), Commercial Sex Acts       23\n",
      "Human Trafficking, Commercial Sex Acts           13\n",
      "Larceny Theft                                 76070\n",
      "Liquor Laws                                      15\n",
      "Lost Property                                  7177\n",
      "Malicious Mischief                            17922\n",
      "Miscellaneous Investigation                    2500\n",
      "Missing Person                                 5639\n",
      "Motor Vehicle Theft                           13610\n",
      "Motor Vehicle Theft?                             27\n",
      "Non-Criminal                                  15521\n",
      "Offences Against The Family And Children       3581\n",
      "Other                                          2352\n",
      "Other Miscellaneous                           18716\n",
      "Other Offenses                                 2409\n",
      "Prostitution                                    315\n",
      "Rape                                             51\n",
      "Recovered Vehicle                             10384\n",
      "Robbery                                        6134\n",
      "Sex Offense                                     296\n",
      "Stolen Property                                1391\n",
      "Suicide                                         125\n",
      "Suspicious                                       48\n",
      "Suspicious Occ                                 5344\n",
      "Traffic Collision                               579\n",
      "Traffic Violation Arrest                       2817\n",
      "Vandalism                                       570\n",
      "Vehicle Impounded                               198\n",
      "Vehicle Misplaced                               103\n",
      "Warrant                                        8121\n",
      "Weapons Carrying Etc                           1451\n",
      "Weapons Offence                                  13\n",
      "Weapons Offense                                1740\n",
      "Name: incident_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check consistency\n",
    "# Resource: https://towardsdatascience.com/master-the-most-hated-task-in-ds-ml-3b9779276d7c\n",
    "incident_categories = data_df['incident_category'].value_counts().sort_index()\n",
    "print(incident_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayview       23855\n",
      "Central       35957\n",
      "Ingleside     20694\n",
      "Mission       32466\n",
      "Northern      37023\n",
      "Out of SF      7563\n",
      "Park          12890\n",
      "Richmond      16933\n",
      "Southern      30257\n",
      "Taraval       18291\n",
      "Tenderloin    24362\n",
      "Name: police_district, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "police_districts = data_df['police_district'].value_counts().sort_index()\n",
    "print(police_districts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayview Hunters Point             16488\n",
      "Bernal Heights                     4831\n",
      "Castro/Upper Market                7684\n",
      "Chinatown                          4485\n",
      "Excelsior                          4456\n",
      "Financial District/South Beach    19211\n",
      "Glen Park                          1463\n",
      "Golden Gate Park                   2533\n",
      "Haight Ashbury                     4264\n",
      "Hayes Valley                       7297\n",
      "Inner Richmond                     3385\n",
      "Inner Sunset                       3300\n",
      "Japantown                          2331\n",
      "Lakeshore                          2911\n",
      "Lincoln Park                        404\n",
      "Lone Mountain/USF                  3214\n",
      "Marina                             7393\n",
      "McLaren Park                        317\n",
      "Mission                           25928\n",
      "Mission Bay                        4495\n",
      "Nob Hill                           7515\n",
      "Noe Valley                         2839\n",
      "North Beach                        6710\n",
      "Oceanview/Merced/Ingleside         2539\n",
      "Outer Mission                      3750\n",
      "Outer Richmond                     6081\n",
      "Pacific Heights                    4771\n",
      "Portola                            2951\n",
      "Potrero Hill                       4416\n",
      "Presidio                            633\n",
      "Presidio Heights                   1763\n",
      "Russian Hill                       5609\n",
      "Seacliff                            333\n",
      "South of Market                   19651\n",
      "Sunset/Parkside                    7363\n",
      "Tenderloin                        25258\n",
      "Treasure Island                     867\n",
      "Twin Peaks                         1492\n",
      "Visitacion Valley                  2845\n",
      "West of Twin Peaks                 5233\n",
      "Western Addition                   8255\n",
      "null                                 51\n",
      "Name: analysis_neighborhood, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "neighborhoods = data_df['analysis_neighborhood'].value_counts().sort_index()\n",
    "print(neighborhoods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Finding: In 'incident_category', multiple inconsistencies exists: the word \"Offense\" is sometimes spelled \"Offence\", a \"?\" is appended to \"Motor Vehicle Theft\", and \"(A)\" is inserted into \"Human Trafficking, Commercial Sex Acts.\" Furthermore, the field requires grouping of several categories: \"Drug Violation\" into \"Drug Offense\", \"Other\" and \"Other Offenses\" into \"Other Miscellaneous\", \"Suspicious\" into \"Suspicious Occ\", and \"Weapons Carrying Etc\" into \"Weapons Offense\". In 'analysis_neighborhood', an inconsistency exists across \"null\" and blank values; they are two representations of the same value.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values\n",
    "data_df.fillna({'analysis_neighborhood':'Not Disclosed', 'incident_category':'Not Disclosed'}, inplace=True)\n",
    "data_df['analysis_neighborhood'].replace('null','Not Disclosed', inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix typos\n",
    "data_df['incident_category'].replace(['Offence','\\?',' \\(A\\)'],['Offense','',''], inplace=True, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group similar categories\n",
    "data_df['incident_category'].replace(['Drug Violation','Other','Other Offenses','Suspicious','Weapons Carrying Etc'], \\\n",
    "                                     ['Drug Offense','Other Miscellaneous','Other Miscellaneous','Suspicious Occ', 'Weapons Offense'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by pre and post lockdown\n",
    "pre_df = data_df.loc[data_df['incident_date'] < lockdown_date.strftime('%Y-%m-%d')]\n",
    "post_df = data_df.loc[data_df['incident_date'] >= lockdown_date.strftime('%Y-%m-%d')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Category Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group total incidents by category\n",
    "pre_cat_ser = pre_df.groupby('incident_category')['incident_id'].nunique().rename('pre_incidents')\n",
    "post_cat_ser = post_df.groupby('incident_category')['incident_id'].nunique().rename('post_incidents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate pre and post incidents, calculate percent change\n",
    "cat_df = pd.concat([pre_cat_ser, post_cat_ser], sort=True, axis=1).fillna(0)\n",
    "cat_df['post_incidents'] = cat_df['post_incidents'].astype(int)\n",
    "cat_df.drop(labels='Not Disclosed', axis=0, inplace=True)\n",
    "cat_df['percent_change'] = (cat_df['post_incidents'] - cat_df['pre_incidents']) / cat_df['pre_incidents'] * 100\n",
    "cat_df.sort_values(by=['post_incidents'], ascending=True, inplace=True)\n",
    "cat_df.index = cat_df.index + ' (' + cat_df['post_incidents'].astype(str) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(cat_df.index, cat_df['percent_change'], height=0.5, color='royalblue', align='center')\n",
    "plt.title(f'Category Incidents Post-Lockdown')\n",
    "plt.xlabel('Percent Change YOY')\n",
    "plt.ylabel('Category (Incidents)')\n",
    "plt.xlim(-100, max(100, cat_df['percent_change'].max()))\n",
    "plt.ylim(-0.5, len(cat_df.index)-0.5)\n",
    "plt.tick_params(axis='y',left=False)\n",
    "plt.grid(axis='x', linestyle='--', linewidth=0.5)\n",
    "plt.tight_layout()\n",
    "plt.savefig('img/incidents_category.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Narrow Scope to Crimes of Stolen Property Only**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stolen_types = ['Burglary', 'Larceny Theft', 'Lost Property', 'Motor Vehicle Theft', 'Robbery', 'Stolen Property']\n",
    "#stolen_types = ['Burglary']\n",
    "stolen_pre_df = pre_df.loc[data_df['incident_category'].isin(stolen_types)]\n",
    "stolen_post_df = post_df.loc[data_df['incident_category'].isin(stolen_types)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Map Analysis**<br>\n",
    "Resource: https://jupyter-gmaps.readthedocs.io/en/latest/tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map incidents by latitude and longitude\n",
    "def map_incidents(df):\n",
    "    latlong_df = df[['incident_id', 'latitude', 'longitude']].copy().drop_duplicates().dropna(how='any')\n",
    "    locations = latlong_df[['latitude', 'longitude']].astype(float)\n",
    "    fig_layout_dict = {'width':'1000px', 'height':'1000px', 'border':'1px solid black', 'padding':'5px'}\n",
    "    fig = gmaps.figure(layout=fig_layout_dict)\n",
    "    heat_layer = gmaps.heatmap_layer(locations, dissipating=True, max_intensity=5, point_radius=5)\n",
    "    fig.add_layer(heat_layer)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map pre-lockdown incidents\n",
    "map_incidents(stolen_pre_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map post-lockdown incidents\n",
    "map_incidents(stolen_post_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neighborhood Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group incidents by neighborhood\n",
    "def chart_neighborhood_incidents(df, timing):\n",
    "    district_ser = df.groupby('analysis_neighborhood')['incident_id'].nunique()\n",
    "    district_ser.sort_values(ascending=True, inplace=True)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.barh(district_ser.index, district_ser, height=0.5, color='royalblue', align='center')\n",
    "    plt.title(f'Neighborhood Incidents {timing}-Lockdown')\n",
    "    plt.xlabel('Incidents')\n",
    "    plt.ylabel('Neighborhood')\n",
    "    plt.ylim(-0.5, len(district_ser)-0.5)\n",
    "    plt.tick_params(axis='y',left=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/incidents_neighborhood_{timing.lower()}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart pre-lockdown incidents\n",
    "chart_neighborhood_incidents(stolen_pre_df, 'Pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Chart post-lockdown incidents\n",
    "chart_neighborhood_incidents(stolen_post_df, 'Post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Time Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group total incidents by day and hour\n",
    "def chart_time_incidents(start_date, end_date, df, timing):\n",
    "    \n",
    "    # Count occurrence of each day of week within date range\n",
    "    # Resource: https://numpy.org/doc/stable/reference/generated/numpy.busday_count.html\n",
    "    days_dict = {}\n",
    "    def day_counter(start_date, end_date, day):\n",
    "        day_count = np.busday_count(start_date, end_date+timedelta(days=1), weekmask=day)\n",
    "        return day_count\n",
    "    for day in days:\n",
    "        days_dict[day] = day_counter(start_date, end_date, day)\n",
    "    \n",
    "    # Group total incidents by day and hour\n",
    "    # Resource: https://www.javaer101.com/en/article/17171715.html\n",
    "    time_df = df[['incident_day_of_week', 'incident_time', 'incident_id']].copy().drop_duplicates()\n",
    "    day_cats = pd.api.types.CategoricalDtype(categories=days, ordered=True)\n",
    "    time_df['day_abbr'] = time_df['incident_day_of_week'].str[:3].astype(day_cats)\n",
    "    time_df['incident_hour'] = time_df['incident_time'].str[:2].astype(int)\n",
    "    time_ser = time_df.groupby(['day_abbr', 'incident_hour'])['incident_id'].nunique().astype(float)\n",
    "    \n",
    "    # Convert total incidents to average incidents by weekday and hour\n",
    "    def day_count_divisor(day):\n",
    "        time_ser[day] = time_ser.loc[day].divide(days_dict[day], level='day_abbr')\n",
    "    for day in days:\n",
    "        day_count_divisor(day)\n",
    "\n",
    "    # Plot\n",
    "    time_ser.unstack(level=0).plot(\n",
    "        kind='line',\n",
    "        figsize=(12,8),\n",
    "        title=f'Average Hourly Incidents {timing}-Lockdown')\n",
    "    plt.xlabel('Hour')\n",
    "    plt.ylabel('Average Incidents')\n",
    "    plt.ylim(0, time_ser.max()*1.2)\n",
    "    plt.xticks(np.arange(0,24,2))\n",
    "    plt.legend(title='Day of Week')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'img/incidents_hourly_{timing.lower()}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chart_time_incidents(start_date, lockdown_date-timedelta(days=1), stolen_pre_df, 'Pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart_time_incidents(lockdown_date, end_date, stolen_post_df, 'Post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
